# A Simple Framework for Contrastive Learning of Visual Representations

## Abstract
- This paper presents SimCLR: a simple framework for contrastive learning of visual representations.
  - Simplified proposed contrastive selfsupervised learning algorithms without requiring specialized architectures or a memory bank.
- What enables the contrastive prediction tasks to learn useful representations?
	- (1) Composition of data augmentations
	- (2) Introduce a learnable nonlinear transformation 
	- (3) Larger batch sizes and mor training steps
- By combining this, we can considerably outperform previous method for self-supervised & semi-supervied learning on ImageNet.
<p align="center"><img src = "https://user-images.githubusercontent.com/88715406/155086702-17a7af0f-5e85-4098-8caf-370860305411.png" width = "60%" height = "60%"></p>

